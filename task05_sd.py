# -*- coding: utf-8 -*-
"""Task05_SD.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1upilh41Zo4XXH3V1Ve4CNwk-KcLXZ7r3
"""

import requests
from bs4 import BeautifulSoup
import csv

BASE_URL = "https://books.toscrape.com/catalogue/page-{}.html"

def scrape_books():
    books = []

    for page in range(1, 6):  # Scrape first 5 pages
        url = BASE_URL.format(page)
        response = requests.get(url)
        soup = BeautifulSoup(response.text, "html.parser")

        articles = soup.find_all("article", class_="product_pod")

        for article in articles:
            name = article.h3.a["title"]
            price = article.find("p", class_="price_color").text
            rating_class = article.find("p", class_="star-rating")["class"]
            rating = rating_class[1]  # e.g., 'Three', 'Five'

            books.append([name, price, rating])

    return books


def save_to_csv(data):
    with open("products.csv", mode="w", newline="", encoding="utf-8") as file:
        writer = csv.writer(file)
        writer.writerow(["Product Name", "Price", "Rating"])
        writer.writerows(data)


def main():
    print("Scraping data...")
    data = scrape_books()
    save_to_csv(data)
    print("âœ… Data saved to products.csv")


if __name__ == "__main__":
    main()